# Equilybrium (name pending)

TL;DR: Equilybrium is a solution that monitors your files and their backup in a flexible way.

I need a solution with following requirements:

1. Computer *A* backs up files from local folders $\left\{ a_i \right\}$ to computer/NAS *B* remote folders $\left\{ b_j \right\}$.
    > $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$ to be defined in configuration file

2. Be file location agnostic: How/Where exactly files from *A* are synced to *B* is no concern of Equilybrium

3. Files in $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$ need to be **monitored** to ensure that **all** files from *A* are **correctly** backed up to *B*.

4. For multiple reasons (performance, practical, etc), an instance of Equilybrium must run on both *A* and *B*

5. Run on any system with Python ($\geq 3.6$) installed, without admin privileges. OS targeted: ``Windows``, ``Synology DSM (Linux)``

6. Alert the user on changes and issues: file added, removed, renamed/moved, modified/corrupted, hash collision

7. Ability to operate on a synced (mirrored) folder: Equilybrium running on *A* and *B* (and their generated files) must coexist

8. Low RAM requirements: to run in low-end systems

9. Give user choice of hashing algorithm: for performance and hash collision considerations

Note: Equilybrium is intended to be used as an addition to sync/backup software such as ``FreeFileSync`` or equivalent.


## *A*/*B* behavioural differences

The need for them follows from ``requirement 4``:

- *A*'s instance may generate a report (see ``requirement 1,6``)

- Different generated file names (see ``requirement 3,7``)

- Different monitored directories (see ``requirement 1,2``)


## Files

- ``equilybrium<-dev>.py``: the main program (optional 'dev' suffix)

- ``equilybrium.config.ini``: INI-style configuration file

- ``equilybrium.requirements.txt``: pip-compatible requirements for easy install

- ``equilybrium.<A|B>.DB.json``: Monitoring database generated by *A*/*B* instances

- ``equilybrium.<A|B>.Event.<event_type>.log``: Logs monitoring events generated by *A*/*B* instances, by event type

- ``equilybrium.report.txt``: Comprehensive report, by sections of date and subsections of Event; Must be appended, not overwritten.

## About hashing

The following algorithms are available, from libraries:

- ``hashlib``: md5, sha1, sha224, sha256, sha384, sha512, blake2b, blake2s, sha3_224, sha3_256, sha3_384, sha3_512

- ``zlib``: crc32, adler32

Some algorithms were tested against other software to confirm they yield the correct digest and the code path is correct.

Choosing an algorithm: you should take into account at least the following considerations:

- **performance**: varies greatly between algorithms, and while the CPU is busy computing them, the storage is mostly idle.

- **digest length**: a longer digest has higher entropy, meaning that the chance of two files having the same digest (undesirable) falls sharply as they get longer. Algorithms from ``zlib`` feature a 32 bit long digest which may not be enough for some users. A longer digest also results in a larger database $M$ file !

## About Monitoring

Monitioring should be done using hashing: any file content modification can be detected by computing a file's actual digest/hash to a reference. Any deviation indicates that the file was changed/corrupted.

- Let's call the monitoring database $M$ and its entries $m$ (referring to the file that is being monitored by this entry)

- $m$ should include the file's size in order to reduce the chance of *hash collisions*.

- $m$ should include the file's location to detect moved/renamed files.

- Monitoring may take action in the following cases: 

    - **new file was detected**: During the verification of $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$, an unmonitored file is found. It should be added to monitoring and the user may be alerted.

    - **file hash verification failed**: During the verification of $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$, a monitored file's computed digest/hash doesn't match its value stored in $m$. The user may be alerted.
      > Note: the modified/corrupted file also triggers a ``NewFile`` event.

    - **file was moved/renamed**: During the verification of $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$, a monitored file's actual path doesn't match its value stored in $m$. The file's location should be updated and the user may be alerted.
      > Note: due to the partial nature of stored paths, a file may be moved to another location in a way that yields no change of partial path, therefore not triggering a ``FileMovedOrRenamed`` event.

    - **file cannot be found**: After the verification of $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$, an entry $m$ wasn't verified. This indicates the file was removed. The user may be alerted.

    - **hash collision**:  During the verification of $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$, a monitored file's actual size doesn't match its value stored in $m$. This may indicate a hash collision (multiple files having the same digest; extremely unlikely but possible) and this verification step should probably be done before the move/rename check. The user may be alerted.

### Database $M$

Required database for monitoring and verification of file integrity.

- Proposed storage: ``JSON`` file containing a single dictionnary with entries $m$.

- Proposed syntax for entries $m$:
    ```Python
    <hash:str>: {
        'size': <size:int>,
        'path': <path:str>
    }
    ```

- The exact hash algorithm and code path should be chosen as a compromise between performance, entropy/length (higher diminishes risks of collision but costs more to store) and other relevant considerations

- Property: $M$ should have exactly the same contents independant of the machine it was generated on (*A* or *B*; use POSIX path)

### Configuration file

Defines set of directories $\left\{ a_i \right\}$ and $\left\{ b_j \right\}$.

- Format style: INI + JSON (to interpret lists)

- Unique and shared between *A* and *B* (see ``requirement 7``)

- ``Settings`` section: Establishes IDs for *A* and *B* to differentiate their behaviour
  > Current solution for creating/verifying IDs: ``import uuid; uuid.getnode()`` in Python (an okay cross-plaform solution for making system IDs)<br/>More methods may be implemented

    ```
    [Settings]
    # System IDs are required for Equilybrium to identify their role and create their files
    # `ID method`: for now, only 'Python uuid' is implemented
    ID method = Python uuid
    A = 123456789
    B = 924784692
    # Hashing settings
    # `Hash algorithm` must be one of: 'md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512' (without quotes)
    Hash algorithm = sha256
    # Can be any integer; only edit this value if you determined it is suboptimal on your systems
    Block size = 2 ** 18
    ```

- ``Monitored Directories`` section

    ```
    [Monitored Directories]
    # Which directories contains files to monitor, on each system ?
    # List here between double quotes the absolute path to these folders
    # example:
    A = [
        "D:/video",
        "F:/myvideos"
        ]
    B = [
        "/private/videos",
        "/public/movies and series"
        ]
    ```

## Parameters, performance testing, advice

### Hashing: Algorithms

The ``sha3`` and ``blake`` families of algorithms, plus any algorithm producing $>256$ bit digests, are rather slow, surely too slow for monitoring purposes. ``adler32`` is consistently the fastest by far, but its 32 bit long digest is probably insufficient and it's only described as "almost as reliable as a CRC32".

**Recommendation**: ``hashlib.sha1`` or ``hashlib.sha256`` for decently fast with longer digest, or ``zlib.adler32`` for maximum speed. Or better: test algorithm speed on your system with ``algo_test.py`` and make your own informed compromise!

### Hashing: Block size

$2^{16}$ (64 KiB) to $2^{20}$ (1 MiB) seem to yield optimal results (tested on HDDs and SSDs). Only powers of $2$ were tested.

**Recommendation**: $2^{18}$ (256KiB; in Python: ``2**18``). Or better: test algorithm speed on your system with ``block_test_*.py`` (don't forget to select the correct script for your hashing algorithm choice and set it as ``HASH_ALGO`` in it) and make your own informed compromise!

### Disk activity

A few tests on consumer-grade HDDs were performed and show a $90-94\%$ activity rate while using parameters: block size $2^{18}$, algorithm ``adler32`` on a collection of large (>100MB) files. Throughput was very close to synthetic benchmark sequential read speed.